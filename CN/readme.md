# NLPLearning-CNWordSegmentation
Re:Zero − 从零开始搭建一个分词工具

多语言: [English](../README.md) | 简体中文

这是一个用于存储中文分词工具的仓库
我是用了两种方式构建此工具，他们分别是简单枚举方法和基于维特比算法。

我使用两种方法构建基于枚举算法的分词方式，他们分别是基于用户输入的和基于词典的。

你可以访问enumerate_old文件来查看基于词典的方式, 访问enumerate文件来查看基于输入的方式。

下边是文件目录
- [基于输入的简单枚举方式](../enumerate.ipynb)
- [基于字典的简单枚举方式](../enumerate_old.ipynb)
- [基于维特比算法的方式](../viterbi.ipynb)

在目录`../data/`下的文件为用作词典的文件

有任何疑问都可以参考[我的blog的这篇文章](https://blog.cha.moe/article/cec83ef9.html)，或者在留言区提问，我会第一时间进行回复。
